{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sbn\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0           101348.88       1  \n",
       "1           112542.58       0  \n",
       "2           113931.57       1  \n",
       "3            93826.63       0  \n",
       "4            79084.10       0  \n",
       "...               ...     ...  \n",
       "9995         96270.64       0  \n",
       "9996        101699.77       0  \n",
       "9997         42085.58       1  \n",
       "9998         92888.52       1  \n",
       "9999         38190.78       0  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#categorizing the independent and dependent variable into x and y respectively\n",
    "x = dataset.iloc[:,3:13].values\n",
    "y = dataset.iloc[:,-1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 10)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encoding categorical variables\n",
    "x = pd.DataFrame(x)\n",
    "encoder = ColumnTransformer([('onehot', OneHotEncoder(), [1,2])], remainder= 'passthrough' )\n",
    "x = np.array(encoder.fit_transform(x), dtype = np.int)\n",
    "x = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2  3  4    5   6   7       8  9  10  11      12\n",
       "0     1  0  0  1  0  619  42   2       0  1   1   1  101348\n",
       "1     0  0  1  1  0  608  41   1   83807  1   0   1  112542\n",
       "2     1  0  0  1  0  502  42   8  159660  3   1   0  113931\n",
       "3     1  0  0  1  0  699  39   1       0  2   0   0   93826\n",
       "4     0  0  1  1  0  850  43   2  125510  1   1   1   79084\n",
       "...  .. .. .. .. ..  ...  ..  ..     ... ..  ..  ..     ...\n",
       "9995  1  0  0  0  1  771  39   5       0  2   1   0   96270\n",
       "9996  1  0  0  0  1  516  35  10   57369  1   1   1  101699\n",
       "9997  1  0  0  1  0  709  36   7       0  1   0   1   42085\n",
       "9998  0  1  0  0  1  772  42   3   75075  2   1   0   92888\n",
       "9999  1  0  0  1  0  792  28   4  130142  1   1   0   38190\n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>771</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>516</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>709</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>772</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>792</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0  1  2    3   4   5       6  7  8  9      10\n",
       "0     0  0  0  619  42   2       0  1  1  1  101348\n",
       "1     0  1  0  608  41   1   83807  1  0  1  112542\n",
       "2     0  0  0  502  42   8  159660  3  1  0  113931\n",
       "3     0  0  0  699  39   1       0  2  0  0   93826\n",
       "4     0  1  0  850  43   2  125510  1  1  1   79084\n",
       "...  .. .. ..  ...  ..  ..     ... .. .. ..     ...\n",
       "9995  0  0  1  771  39   5       0  2  1  0   96270\n",
       "9996  0  0  1  516  35  10   57369  1  1  1  101699\n",
       "9997  0  0  0  709  36   7       0  1  0  1   42085\n",
       "9998  1  0  1  772  42   3   75075  2  1  0   92888\n",
       "9999  0  0  0  792  28   4  130142  1  1  0   38190\n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop two dummy variable one from each category\n",
    "x = x.drop(columns=[0])\n",
    "x = x.drop(columns=[3])\n",
    "x = x.iloc[:].values\n",
    "x = pd.DataFrame(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splict the x and y dataset into training and testing set\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size= 0.25, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature scaling the training and test set\n",
    "\n",
    "feascale = StandardScaler()\n",
    "x_train = feascale.fit_transform(x_train)\n",
    "x_test = feascale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding the input and the hidden layer of the ANN and the output layer\n",
    "classifier.add(Dense(6, kernel_initializer='glorot_uniform', activation='relu', input_shape=(11,)))\n",
    "classifier.add(Dense(6, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "classifier.add(Dense(6, kernel_initializer='glorot_uniform', activation='relu'))\n",
    "classifier.add(Dense(1, kernel_initializer='glorot_uniform', activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configuring the ANN model\n",
    "classifier.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.5017 - accuracy: 0.7957\n",
      "Epoch 2/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.4526 - accuracy: 0.7963 0s - loss: 0.4519 - accu\n",
      "Epoch 3/100\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4408 - accuracy: 0.7963\n",
      "Epoch 4/100\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4331 - accuracy: 0.7963\n",
      "Epoch 5/100\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.4269 - accuracy: 0.7963\n",
      "Epoch 6/100\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.4198 - accuracy: 0.7971\n",
      "Epoch 7/100\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.4116 - accuracy: 0.8141\n",
      "Epoch 8/100\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.4009 - accuracy: 0.8283 0s - loss: 0.4044 - accura\n",
      "Epoch 9/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3905 - accuracy: 0.8368\n",
      "Epoch 10/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3823 - accuracy: 0.8419\n",
      "Epoch 11/100\n",
      "7500/7500 [==============================] - 1s 72us/step - loss: 0.3766 - accuracy: 0.8467\n",
      "Epoch 12/100\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3725 - accuracy: 0.8507\n",
      "Epoch 13/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3687 - accuracy: 0.8527\n",
      "Epoch 14/100\n",
      "7500/7500 [==============================] - 1s 70us/step - loss: 0.3660 - accuracy: 0.8535\n",
      "Epoch 15/100\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.3632 - accuracy: 0.8575\n",
      "Epoch 16/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3609 - accuracy: 0.8555\n",
      "Epoch 17/100\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3593 - accuracy: 0.8555\n",
      "Epoch 18/100\n",
      "7500/7500 [==============================] - 1s 71us/step - loss: 0.3575 - accuracy: 0.8575\n",
      "Epoch 19/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3560 - accuracy: 0.8589\n",
      "Epoch 20/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3548 - accuracy: 0.8596\n",
      "Epoch 21/100\n",
      "7500/7500 [==============================] - 1s 93us/step - loss: 0.3536 - accuracy: 0.8573\n",
      "Epoch 22/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3527 - accuracy: 0.8592\n",
      "Epoch 23/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3516 - accuracy: 0.8576\n",
      "Epoch 24/100\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.3510 - accuracy: 0.8587\n",
      "Epoch 25/100\n",
      "7500/7500 [==============================] - 1s 95us/step - loss: 0.3505 - accuracy: 0.8599\n",
      "Epoch 26/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3494 - accuracy: 0.8604\n",
      "Epoch 27/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3492 - accuracy: 0.8599\n",
      "Epoch 28/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3490 - accuracy: 0.8601\n",
      "Epoch 29/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3480 - accuracy: 0.8609\n",
      "Epoch 30/100\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.3478 - accuracy: 0.8595\n",
      "Epoch 31/100\n",
      "7500/7500 [==============================] - 1s 101us/step - loss: 0.3477 - accuracy: 0.8597\n",
      "Epoch 32/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3468 - accuracy: 0.8609\n",
      "Epoch 33/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3471 - accuracy: 0.8604\n",
      "Epoch 34/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3453 - accuracy: 0.8624\n",
      "Epoch 35/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3459 - accuracy: 0.8596\n",
      "Epoch 36/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3444 - accuracy: 0.8615\n",
      "Epoch 37/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3447 - accuracy: 0.8621\n",
      "Epoch 38/100\n",
      "7500/7500 [==============================] - 1s 90us/step - loss: 0.3440 - accuracy: 0.8619\n",
      "Epoch 39/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3431 - accuracy: 0.8641\n",
      "Epoch 40/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3432 - accuracy: 0.8600\n",
      "Epoch 41/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3433 - accuracy: 0.8619\n",
      "Epoch 42/100\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.3429 - accuracy: 0.8631\n",
      "Epoch 43/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3421 - accuracy: 0.8616\n",
      "Epoch 44/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3427 - accuracy: 0.8631\n",
      "Epoch 45/100\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.3421 - accuracy: 0.8628\n",
      "Epoch 46/100\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.3421 - accuracy: 0.8604\n",
      "Epoch 47/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3420 - accuracy: 0.8616\n",
      "Epoch 48/100\n",
      "7500/7500 [==============================] - 1s 87us/step - loss: 0.3415 - accuracy: 0.8623\n",
      "Epoch 49/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3415 - accuracy: 0.8636\n",
      "Epoch 50/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3417 - accuracy: 0.8607\n",
      "Epoch 51/100\n",
      "7500/7500 [==============================] - ETA: 0s - loss: 0.3399 - accuracy: 0.86 - 1s 86us/step - loss: 0.3407 - accuracy: 0.8637\n",
      "Epoch 52/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3408 - accuracy: 0.8647\n",
      "Epoch 53/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3406 - accuracy: 0.8643\n",
      "Epoch 54/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3406 - accuracy: 0.8631\n",
      "Epoch 55/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3407 - accuracy: 0.8628\n",
      "Epoch 56/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3402 - accuracy: 0.8628\n",
      "Epoch 57/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3400 - accuracy: 0.8628\n",
      "Epoch 58/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3403 - accuracy: 0.8631\n",
      "Epoch 59/100\n",
      "7500/7500 [==============================] - 1s 86us/step - loss: 0.3402 - accuracy: 0.8645\n",
      "Epoch 60/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3397 - accuracy: 0.8644\n",
      "Epoch 61/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3395 - accuracy: 0.8641\n",
      "Epoch 62/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3405 - accuracy: 0.8637\n",
      "Epoch 63/100\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.3395 - accuracy: 0.8643\n",
      "Epoch 64/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3393 - accuracy: 0.8635\n",
      "Epoch 65/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3395 - accuracy: 0.8636\n",
      "Epoch 66/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3388 - accuracy: 0.8639\n",
      "Epoch 67/100\n",
      "7500/7500 [==============================] - 1s 91us/step - loss: 0.3384 - accuracy: 0.8625\n",
      "Epoch 68/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3388 - accuracy: 0.8656\n",
      "Epoch 69/100\n",
      "7500/7500 [==============================] - 1s 78us/step - loss: 0.3395 - accuracy: 0.8631\n",
      "Epoch 70/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3384 - accuracy: 0.8641\n",
      "Epoch 71/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3378 - accuracy: 0.8649\n",
      "Epoch 72/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3395 - accuracy: 0.8629\n",
      "Epoch 73/100\n",
      "7500/7500 [==============================] - 1s 92us/step - loss: 0.3387 - accuracy: 0.8645\n",
      "Epoch 74/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3391 - accuracy: 0.8627\n",
      "Epoch 75/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3391 - accuracy: 0.8628\n",
      "Epoch 76/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3387 - accuracy: 0.8643\n",
      "Epoch 77/100\n",
      "7500/7500 [==============================] - 1s 81us/step - loss: 0.3390 - accuracy: 0.8657\n",
      "Epoch 78/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3395 - accuracy: 0.8607\n",
      "Epoch 79/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3377 - accuracy: 0.8653\n",
      "Epoch 80/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3400 - accuracy: 0.8644\n",
      "Epoch 81/100\n",
      "7500/7500 [==============================] - 1s 73us/step - loss: 0.3392 - accuracy: 0.8625\n",
      "Epoch 82/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3384 - accuracy: 0.8628\n",
      "Epoch 83/100\n",
      "7500/7500 [==============================] - 1s 84us/step - loss: 0.3396 - accuracy: 0.8641\n",
      "Epoch 84/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3395 - accuracy: 0.8631\n",
      "Epoch 85/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3396 - accuracy: 0.8623\n",
      "Epoch 86/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3389 - accuracy: 0.8633\n",
      "Epoch 87/100\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.3382 - accuracy: 0.8647\n",
      "Epoch 88/100\n",
      "7500/7500 [==============================] - 1s 75us/step - loss: 0.3389 - accuracy: 0.8616\n",
      "Epoch 89/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3391 - accuracy: 0.8663\n",
      "Epoch 90/100\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.3387 - accuracy: 0.8632\n",
      "Epoch 91/100\n",
      "7500/7500 [==============================] - 1s 74us/step - loss: 0.3391 - accuracy: 0.8617\n",
      "Epoch 92/100\n",
      "7500/7500 [==============================] - 1s 80us/step - loss: 0.3389 - accuracy: 0.8648\n",
      "Epoch 93/100\n",
      "7500/7500 [==============================] - 1s 76us/step - loss: 0.3388 - accuracy: 0.8645\n",
      "Epoch 94/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3391 - accuracy: 0.8644\n",
      "Epoch 95/100\n",
      "7500/7500 [==============================] - 1s 79us/step - loss: 0.3384 - accuracy: 0.8648\n",
      "Epoch 96/100\n",
      "7500/7500 [==============================] - 1s 77us/step - loss: 0.3388 - accuracy: 0.8640\n",
      "Epoch 97/100\n",
      "7500/7500 [==============================] - 1s 82us/step - loss: 0.3391 - accuracy: 0.8651\n",
      "Epoch 98/100\n",
      "7500/7500 [==============================] - 1s 83us/step - loss: 0.3387 - accuracy: 0.8637\n",
      "Epoch 99/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3393 - accuracy: 0.8644\n",
      "Epoch 100/100\n",
      "7500/7500 [==============================] - 1s 85us/step - loss: 0.3395 - accuracy: 0.8636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18ab4cea9c8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit the the training set to the ANN\n",
    "classifier.fit(x_train, y_train, batch_size=10, epochs= 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the trained model to test the testing sets\n",
    "y_pred = classifier.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#construccting the confuction metrix\n",
    "confmetrix = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1885,  106],\n",
       "       [ 249,  260]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmetrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.858"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1885+ 260)/2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "axe = axe.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<matplotlib.axes._subplots.AxesSubplot object at 0x000002075C76B148>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000002075C923708>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000002075CBEF9C8>,\n",
       "       ...,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x000002077376B1C8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000207737A43C8>,\n",
       "       <matplotlib.axes._subplots.AxesSubplot object at 0x00000207737DC588>],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.arange(0,15*15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "       169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "       182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "       195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "       208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "       221, 222, 223, 224])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "f, axes = plt.subplots(1,2)  # 1 row containing 2 subplots.\n",
    "\n",
    "# Plot random points on one subplots.\n",
    "axes[0].scatter(np.random.randn(10), np.random.randn(10))\n",
    "\n",
    "# Plot histogram on the other one.\n",
    "axes[1].hist(np.random.randn(100))\n",
    "\n",
    "# Adjust the size and layout through the Figure-object.\n",
    "f.set_size_inches(10, 5)\n",
    "f.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matplotlib.figure.Figure"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
